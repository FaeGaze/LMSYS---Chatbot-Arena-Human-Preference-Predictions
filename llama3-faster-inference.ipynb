{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254ca8d2",
   "metadata": {
    "papermill": {
     "duration": 0.011554,
     "end_time": "2024-08-05T03:42:47.681287",
     "exception": false,
     "start_time": "2024-08-05T03:42:47.669733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0aa132d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:42:47.704732Z",
     "iopub.status.busy": "2024-08-05T03:42:47.704462Z",
     "iopub.status.idle": "2024-08-05T03:43:40.233984Z",
     "shell.execute_reply": "2024-08-05T03:43:40.232975Z"
    },
    "papermill": {
     "duration": 52.543751,
     "end_time": "2024-08-05T03:43:40.236368",
     "exception": false,
     "start_time": "2024-08-05T03:42:47.692617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115f0d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:43:40.261392Z",
     "iopub.status.busy": "2024-08-05T03:43:40.260644Z",
     "iopub.status.idle": "2024-08-05T03:44:00.680583Z",
     "shell.execute_reply": "2024-08-05T03:44:00.679790Z"
    },
    "papermill": {
     "duration": 20.434737,
     "end_time": "2024-08-05T03:44:00.682917",
     "exception": false,
     "start_time": "2024-08-05T03:43:40.248180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 03:43:52.056387: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 03:43:52.056486: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 03:43:52.196209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb500e56",
   "metadata": {
    "papermill": {
     "duration": 0.01097,
     "end_time": "2024-08-05T03:44:00.705672",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.694702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "According to the pytorch [documentation](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html?highlight=scaled_dot_product#torch.nn.functional.scaled_dot_product_attention), `scaled_dot_product_attention` automatically select the most optimal implementation from:\n",
    "1. Flash Attention\n",
    "2. Memory Efficient Attention\n",
    "3. A PyTorch (naive) implementation\n",
    "\n",
    "By default, all of those are enabled but we can also manually enable/disable certain backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15c11c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:00.729929Z",
     "iopub.status.busy": "2024-08-05T03:44:00.729410Z",
     "iopub.status.idle": "2024-08-05T03:44:00.734205Z",
     "shell.execute_reply": "2024-08-05T03:44:00.733388Z"
    },
    "papermill": {
     "duration": 0.018675,
     "end_time": "2024-08-05T03:44:00.735972",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.717297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert torch.cuda.device_count() == 2, \"Sorry - multi-GPU required!\"\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "torch.backends.cuda.enable_flash_sdp(True)  # Doesn't have any effect as Flash Attention does not support T4/P100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ed53e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:00.764700Z",
     "iopub.status.busy": "2024-08-05T03:44:00.764422Z",
     "iopub.status.idle": "2024-08-05T03:44:00.769510Z",
     "shell.execute_reply": "2024-08-05T03:44:00.768688Z"
    },
    "papermill": {
     "duration": 0.02241,
     "end_time": "2024-08-05T03:44:00.771322",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.748912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_name = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "    weights_path = '/kaggle/input/lmsys-finetuned-all/llama_3_finetuned_model_all-2.pth'  #'/kaggle/input/lmsys-1664-all/llama_3_finetuned_model_all.pth'\n",
    "    max_length = 1664\n",
    "    batch_size = 4\n",
    "    device = torch.device(\"cuda\")    \n",
    "    tta = False  # test time augmentation. <prompt>-<model-b's response>-<model-a's response>\n",
    "    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149dcbc9",
   "metadata": {
    "papermill": {
     "duration": 0.010965,
     "end_time": "2024-08-05T03:44:00.793465",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.782500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d56313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:00.816713Z",
     "iopub.status.busy": "2024-08-05T03:44:00.816453Z",
     "iopub.status.idle": "2024-08-05T03:44:00.849075Z",
     "shell.execute_reply": "2024-08-05T03:44:00.848217Z"
    },
    "papermill": {
     "duration": 0.046313,
     "end_time": "2024-08-05T03:44:00.850865",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.804552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>I have three oranges today, I ate an orange ye...</td>\n",
       "      <td>You have two oranges today.</td>\n",
       "      <td>You still have three oranges. Eating an orange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>You are a mediator in a heated political debat...</td>\n",
       "      <td>Thank you for sharing the details of the situa...</td>\n",
       "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>How to initialize the classification head when...</td>\n",
       "      <td>When you want to initialize the classification...</td>\n",
       "      <td>To initialize the classification head when per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   136060  I have three oranges today, I ate an orange ye...   \n",
       "1   211333  You are a mediator in a heated political debat...   \n",
       "2  1233961  How to initialize the classification head when...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                        You have two oranges today.   \n",
       "1  Thank you for sharing the details of the situa...   \n",
       "2  When you want to initialize the classification...   \n",
       "\n",
       "                                          response_b  \n",
       "0  You still have three oranges. Eating an orange...  \n",
       "1  Mr Reddy and Ms Blue both have valid points in...  \n",
       "2  To initialize the classification head when per...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# concatenate strings in list\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "display(test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca35ca",
   "metadata": {
    "papermill": {
     "duration": 0.011148,
     "end_time": "2024-08-05T03:44:00.873405",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.862257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc778ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:00.899992Z",
     "iopub.status.busy": "2024-08-05T03:44:00.899674Z",
     "iopub.status.idle": "2024-08-05T03:44:00.910940Z",
     "shell.execute_reply": "2024-08-05T03:44:00.910069Z"
    },
    "papermill": {
     "duration": 0.02893,
     "end_time": "2024-08-05T03:44:00.913624",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.884694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    prompt = [\"User prompt: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\nModel A :\\n\" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n--------\\n\\nModel B:\\n\" + r_b for r_b in response_b]\n",
    "    if spread_max_length:\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]\n",
    "    else:\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69664af1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:00.946288Z",
     "iopub.status.busy": "2024-08-05T03:44:00.945914Z",
     "iopub.status.idle": "2024-08-05T03:44:01.525212Z",
     "shell.execute_reply": "2024-08-05T03:44:01.524275Z"
    },
    "papermill": {
     "duration": 0.596859,
     "end_time": "2024-08-05T03:44:01.527365",
     "exception": false,
     "start_time": "2024-08-05T03:44:00.930506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 57 ms, total: 477 ms\n",
      "Wall time: 571 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# swap response_a & response_b\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5760d4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:01.552263Z",
     "iopub.status.busy": "2024-08-05T03:44:01.551987Z",
     "iopub.status.idle": "2024-08-05T03:44:01.557737Z",
     "shell.execute_reply": "2024-08-05T03:44:01.556738Z"
    },
    "papermill": {
     "duration": 0.020335,
     "end_time": "2024-08-05T03:44:01.559620",
     "exception": false,
     "start_time": "2024-08-05T03:44:01.539285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\n",
      "\n",
      "Model A :\n",
      "You have two oranges today.\n",
      "\n",
      "--------\n",
      "\n",
      "Model B:\n",
      "You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(data[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c128dc6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:01.584086Z",
     "iopub.status.busy": "2024-08-05T03:44:01.583621Z",
     "iopub.status.idle": "2024-08-05T03:44:01.588733Z",
     "shell.execute_reply": "2024-08-05T03:44:01.587926Z"
    },
    "papermill": {
     "duration": 0.019478,
     "end_time": "2024-08-05T03:44:01.590723",
     "exception": false,
     "start_time": "2024-08-05T03:44:01.571245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\n",
      "\n",
      "Model A :\n",
      "You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\n",
      "\n",
      "--------\n",
      "\n",
      "Model B:\n",
      "You have two oranges today.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(aug_data[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb0bb5",
   "metadata": {
    "papermill": {
     "duration": 0.01161,
     "end_time": "2024-08-05T03:44:01.614056",
     "exception": false,
     "start_time": "2024-08-05T03:44:01.602446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load model \n",
    "We load 1 model on each gpu.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb8bb17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:44:01.638752Z",
     "iopub.status.busy": "2024-08-05T03:44:01.638492Z",
     "iopub.status.idle": "2024-08-05T03:45:47.467071Z",
     "shell.execute_reply": "2024-08-05T03:45:47.466171Z"
    },
    "papermill": {
     "duration": 105.843265,
     "end_time": "2024-08-05T03:45:47.469173",
     "exception": false,
     "start_time": "2024-08-05T03:44:01.625908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e703947937b04f558f1a025750b22f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/llama-3/transformers/8b-chat-hf/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4102471f7de3454ca37b32211032c63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/llama-3/transformers/8b-chat-hf/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BitsAndBytes configuration\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False,\n",
    ")\n",
    "# Load base model on GPU 0\n",
    "device_0 = torch.device('cuda:0')\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:0')\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Load base model on GPU 1\n",
    "device_1 = torch.device('cuda:1')\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:1')\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe927cec",
   "metadata": {
    "papermill": {
     "duration": 0.012167,
     "end_time": "2024-08-05T03:45:47.493917",
     "exception": false,
     "start_time": "2024-08-05T03:45:47.481750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2982b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:45:47.519516Z",
     "iopub.status.busy": "2024-08-05T03:45:47.519189Z",
     "iopub.status.idle": "2024-08-05T03:45:47.523819Z",
     "shell.execute_reply": "2024-08-05T03:45:47.522948Z"
    },
    "papermill": {
     "duration": 0.01955,
     "end_time": "2024-08-05T03:45:47.525652",
     "exception": false,
     "start_time": "2024-08-05T03:45:47.506102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    inference_mode=True,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=['o_proj', 'v_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d507074c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:45:47.551095Z",
     "iopub.status.busy": "2024-08-05T03:45:47.550825Z",
     "iopub.status.idle": "2024-08-05T03:46:00.005363Z",
     "shell.execute_reply": "2024-08-05T03:46:00.004508Z"
    },
    "papermill": {
     "duration": 12.469631,
     "end_time": "2024-08-05T03:46:00.007487",
     "exception": false,
     "start_time": "2024-08-05T03:45:47.537856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "              (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=1024, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=3, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=3, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get peft\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device_0) \n",
    "# Load weights\n",
    "model_0.load_state_dict(torch.load(cfg.weights_path), strict=False)\n",
    "model_0.eval()\n",
    "\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device_1)\n",
    "model_1.load_state_dict(torch.load(cfg.weights_path), strict=False)\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bce0bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:46:00.034488Z",
     "iopub.status.busy": "2024-08-05T03:46:00.033831Z",
     "iopub.status.idle": "2024-08-05T03:46:00.046221Z",
     "shell.execute_reply": "2024-08-05T03:46:00.045384Z"
    },
    "papermill": {
     "duration": 0.027934,
     "end_time": "2024-08-05T03:46:00.048174",
     "exception": false,
     "start_time": "2024-08-05T03:46:00.020240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 24,576 || all params: 7,506,653,184 || trainable%: 0.0003273895755885237\n",
      "trainable params: 24,576 || all params: 7,506,653,184 || trainable%: 0.0003273895755885237\n"
     ]
    }
   ],
   "source": [
    "# Trainable Parameters\n",
    "model_0.print_trainable_parameters()\n",
    "model_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b59791",
   "metadata": {
    "papermill": {
     "duration": 0.012376,
     "end_time": "2024-08-05T03:46:00.073017",
     "exception": false,
     "start_time": "2024-08-05T03:46:00.060641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfc74615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:46:00.100149Z",
     "iopub.status.busy": "2024-08-05T03:46:00.099646Z",
     "iopub.status.idle": "2024-08-05T03:46:00.108159Z",
     "shell.execute_reply": "2024-08-05T03:46:00.107383Z"
    },
    "papermill": {
     "duration": 0.023721,
     "end_time": "2024-08-05T03:46:00.109992",
     "exception": false,
     "start_time": "2024-08-05T03:46:00.086271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        outputs = model(**inputs.to(device))\n",
    "        proba = outputs.logits.softmax(-1).cpu()\n",
    "        \n",
    "        a_win.extend(proba[:, 0].tolist())\n",
    "        b_win.extend(proba[:, 1].tolist())\n",
    "        tie.extend(proba[:, 2].tolist())\n",
    "    \n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1d1e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:46:00.135879Z",
     "iopub.status.busy": "2024-08-05T03:46:00.135627Z",
     "iopub.status.idle": "2024-08-05T03:46:03.421856Z",
     "shell.execute_reply": "2024-08-05T03:46:03.420721Z"
    },
    "papermill": {
     "duration": 3.301633,
     "end_time": "2024-08-05T03:46:03.424023",
     "exception": false,
     "start_time": "2024-08-05T03:46:00.122390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.2795207500457764\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "# sort by input length to fully leverage dynaminc padding\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "# the total #tokens in sub_1 and sub_2 should be more or less the same\n",
    "sub_1 = data.iloc[0::2].copy()\n",
    "sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04ed3296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:46:03.452111Z",
     "iopub.status.busy": "2024-08-05T03:46:03.451823Z",
     "iopub.status.idle": "2024-08-05T03:46:03.459360Z",
     "shell.execute_reply": "2024-08-05T03:46:03.458522Z"
    },
    "papermill": {
     "duration": 0.023147,
     "end_time": "2024-08-05T03:46:03.461235",
     "exception": false,
     "start_time": "2024-08-05T03:46:03.438088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.0001823902130126953\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "if cfg.tta:\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)  # sort by input length to boost speed\n",
    "    sub_1 = data.iloc[0::2].copy()\n",
    "    sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "    tta_result_df = pd.concat(list(results), axis=0)\n",
    "    # recall TTA's order is flipped\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n",
    "    # average original result and TTA result.\n",
    "    proba = (proba + tta_proba) / 2\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0716724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T03:46:03.489464Z",
     "iopub.status.busy": "2024-08-05T03:46:03.489173Z",
     "iopub.status.idle": "2024-08-05T03:46:03.505611Z",
     "shell.execute_reply": "2024-08-05T03:46:03.504740Z"
    },
    "papermill": {
     "duration": 0.033302,
     "end_time": "2024-08-05T03:46:03.507602",
     "exception": false,
     "start_time": "2024-08-05T03:46:03.474300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.168747</td>\n",
       "      <td>0.600603</td>\n",
       "      <td>0.230650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.974250</td>\n",
       "      <td>0.023410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.487612</td>\n",
       "      <td>0.236717</td>\n",
       "      <td>0.275671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "2  1233961        0.168747        0.600603    0.230650\n",
       "0   136060        0.002341        0.974250    0.023410\n",
       "1   211333        0.487612        0.236717    0.275671"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]\n",
    "submission_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637d7c2",
   "metadata": {
    "papermill": {
     "duration": 0.01288,
     "end_time": "2024-08-05T03:46:03.533548",
     "exception": false,
     "start_time": "2024-08-05T03:46:03.520668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811df750",
   "metadata": {
    "papermill": {
     "duration": 0.01258,
     "end_time": "2024-08-05T03:46:03.559032",
     "exception": false,
     "start_time": "2024-08-05T03:46:03.546452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5034873,
     "sourceId": 8449074,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5455525,
     "sourceId": 9048497,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5430061,
     "sourceId": 9060803,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5490166,
     "sourceId": 9097087,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496290,
     "sourceId": 9107005,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 202.509982,
   "end_time": "2024-08-05T03:46:07.087466",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-05T03:42:44.577484",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0464b4713568422fb678f6ecdbb87a92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "079bb7cab72b481eb22bf2151379beb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c288fbfbf1a74013b2e86eb0ebb6351c",
       "placeholder": "​",
       "style": "IPY_MODEL_945d0e199df14749a7a0d3c630967a54",
       "value": " 4/4 [00:13&lt;00:00,  2.68s/it]"
      }
     },
     "11280c43fd36454db2486a193bb736fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_351c616f008a4e9ebd6f4c64fd6f16c8",
       "placeholder": "​",
       "style": "IPY_MODEL_419fbdfc1f5442fab4d42e5911c33193",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "351c616f008a4e9ebd6f4c64fd6f16c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a430b9fc9a948f0ac5e9971e65b2118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4102471f7de3454ca37b32211032c63f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f113e63bd7924baea7a1633b737a8d0d",
        "IPY_MODEL_7d6c214f71834aa58a29108c66864d3a",
        "IPY_MODEL_079bb7cab72b481eb22bf2151379beb6"
       ],
       "layout": "IPY_MODEL_7be8aa1a26de432e841ea453559953f1"
      }
     },
     "419fbdfc1f5442fab4d42e5911c33193": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6318476dcbde4ac7934d9dd532554a73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79be87ab8e0146408040d48405ef7174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6318476dcbde4ac7934d9dd532554a73",
       "placeholder": "​",
       "style": "IPY_MODEL_3a430b9fc9a948f0ac5e9971e65b2118",
       "value": " 4/4 [01:31&lt;00:00, 18.68s/it]"
      }
     },
     "7be8aa1a26de432e841ea453559953f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d6c214f71834aa58a29108c66864d3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c3ca3ced462a4da68d83cbe61f35c74f",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ce405e9b8be344bc8b5708299b34b8f3",
       "value": 4.0
      }
     },
     "945d0e199df14749a7a0d3c630967a54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9e1d32e80dd6413fa8ece3bfae4087ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d48e37ee24d44dca977794c7f181e020",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bbe06850a1a945cf97ac1024252be2a8",
       "value": 4.0
      }
     },
     "a31a34c860124c5fb7f81f81225d942b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bbe06850a1a945cf97ac1024252be2a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c288fbfbf1a74013b2e86eb0ebb6351c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3ca3ced462a4da68d83cbe61f35c74f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce405e9b8be344bc8b5708299b34b8f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d48e37ee24d44dca977794c7f181e020": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5ae2a160dde4a888467f7e9e2c9483f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e703947937b04f558f1a025750b22f20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_11280c43fd36454db2486a193bb736fa",
        "IPY_MODEL_9e1d32e80dd6413fa8ece3bfae4087ff",
        "IPY_MODEL_79be87ab8e0146408040d48405ef7174"
       ],
       "layout": "IPY_MODEL_0464b4713568422fb678f6ecdbb87a92"
      }
     },
     "f113e63bd7924baea7a1633b737a8d0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e5ae2a160dde4a888467f7e9e2c9483f",
       "placeholder": "​",
       "style": "IPY_MODEL_a31a34c860124c5fb7f81f81225d942b",
       "value": "Loading checkpoint shards: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
